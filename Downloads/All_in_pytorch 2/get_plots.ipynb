{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot  as plt\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Comb(df):\n",
    "    \n",
    "    med_df = df.drop(columns=['diagnosis'])\n",
    "\n",
    "    # Compute hash only once\n",
    "    df['hash'] = med_df.apply(lambda row: hash(tuple(row)), axis=1)\n",
    "    # Compute risk per unique hash\n",
    "    risk_df = df.groupby('hash', as_index=False)['diagnosis'].agg(risk='mean')\n",
    "    # Merge back with original data and drop hash column\n",
    "    risk_df = df.merge(risk_df, on='hash').drop(columns=['hash'])\n",
    "    #save column order \n",
    "    col = risk_df.pop('diagnosis') \n",
    "    risk_df['diagnosis'] = col\n",
    "\n",
    "    return risk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist_plot(df,frac=0.5, random_state=42):\n",
    "    df_risk_all = get_Comb(df)\n",
    "    df_risk_all.drop(columns=['diagnosis'], inplace=True)\n",
    "    df_risk_all.drop_duplicates(inplace=True)\n",
    "\n",
    "    df_frac = get_Comb(df.sample(frac=frac, random_state=random_state) )\n",
    "    df_frac.drop(columns=['diagnosis'], inplace=True)\n",
    "    df_frac.drop_duplicates(inplace=True)\n",
    "\n",
    "    df_risk_all['hash'] = df_risk_all.drop(columns=['risk']).apply(lambda row: hash(tuple(row)), axis=1)\n",
    "    df_frac['hash'] = df_frac.drop(columns=['risk']).apply(lambda row: hash(tuple(row)), axis=1)\n",
    "    df_merge = pd.merge(df_risk_all[['hash','risk']], df_frac[['hash','risk']], on='hash', how='inner') \n",
    "    error = df_merge['risk_x']-df_merge['risk_y']\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('Data/sparse_med_cleaned.csv')\n",
    "df.drop(columns=['ID','fin_grossesse'], inplace=True)\n",
    "df['hash'] = df.drop(columns=['diagnosis']).apply(lambda row: hash(tuple(row)), axis=1)\n",
    "hash_counts = df['hash'].value_counts()\n",
    "df = df[df['hash'].isin(hash_counts[hash_counts > 2].index)]\n",
    "df = df.reset_index(drop=True)\n",
    "error_25 = get_dist_plot(df, frac=0.25)\n",
    "error_50 = get_dist_plot(df, frac=0.5)\n",
    "error_75 = get_dist_plot(df, frac=0.75)\n",
    "error_100 = get_dist_plot(df, frac=1)\n",
    "\n",
    "df_errors = pd.DataFrame({\n",
    "    '25%': error_25,\n",
    "    '50%': error_50,\n",
    "    '75%': error_75,\n",
    "    '100%': error_100\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(error_25, label=\"25%\", linewidth=2)\n",
    "sns.kdeplot(error_50, label=\"50%\", linewidth=2)\n",
    "sns.kdeplot(error_75, label=\"75%\", linewidth=2)\n",
    "sns.kdeplot(error_100, label=\"100%\", linewidth=2)\n",
    "plt.xlabel(\"Error Values\")\n",
    "#plt.xscale('log')\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Error Distributions\")\n",
    "plt.legend(title=\"Fraction of Data Used\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(data=df_errors)\n",
    "# Formatting\n",
    "plt.xlabel(\"Fraction of Data Used\")\n",
    "plt.ylabel(\"Error Distribution\")\n",
    "plt.title(\"Boxplot of Error Distributions\")\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
